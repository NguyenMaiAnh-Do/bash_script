{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7797f-f5c7-4cee-8848-46cc51f52a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ececee-2d1a-4785-84e8-766a6d7b88d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ndo/bash_output/data_labels/varscan_labels.csv', sep=\",\", encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdbaa1-02a9-4a1a-bdca-9764a6ff1ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels01= df['labels01'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598491d-db5b-4b31-8fbb-97557f301103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "flank=df['1']\n",
    "flank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74736b8",
   "metadata": {},
   "source": [
    "**let's try with k-mers encoding first**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ac37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb85acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize DNA sequences into 4-mers\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(flank)\n",
    "sequences = tokenizer.texts_to_sequences(flank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c90a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sequences obtained from tokenization\n",
    "tokenizer_sequences = sequences\n",
    "\n",
    "# Inverse mapping to convert sequences back to text\n",
    "inverse_word_index = {v: k for k, v in tokenizer.word_index.items()}\n",
    "sequences_text = [[inverse_word_index.get(idx, '') for idx in seq] for seq in tokenizer_sequences]\n",
    "\n",
    "# Create a DataFrame with sequences\n",
    "df = pd.DataFrame({'Sequence': sequences_text})\n",
    "\n",
    "# Write DataFrame to a CSV file\n",
    "csv_filename = '/home/ndo/bash_output/encoded_sequences/4mers_encoded.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sequences from the CSV file\n",
    "df_read = pd.read_csv('/home/ndo/bash_output/encoded_sequences/4mers_encoded.csv')\n",
    "\n",
    "# Retrieve sequences from DataFrame\n",
    "sequences_read = [[tokenizer.word_index.get(char, 0) for char in seq] for seq in df_read['Sequence']]\n",
    "\n",
    "# Display the sequences\n",
    "print(\"Original Sequences:\", tokenizer_sequences)\n",
    "print(\"Sequences Read from CSV:\", sequences_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb835d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' contains your dataset and 'labels' contain corresponding labels\n",
    "\n",
    "# Splitting the data into 80% training and 20% test/validation combined\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(sequences, labels01, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting the test/validation data into 50% test and 50% validation\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Validation set size:\", len(X_val))\n",
    "print(\"Test set size:\", len(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
